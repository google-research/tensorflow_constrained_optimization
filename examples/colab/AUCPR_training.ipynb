{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i4vFDhvn_Bdn"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Constrained Optimization Authors. All Rights Reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "\u003e http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RpUmH2nk_Bdo"
      },
      "source": [
        "## PR-AUC Maximization\n",
        "In this colab, we'll show how to use the TF Constrained Optimization (TFCO) library to train a model to maximize the *Area Under the Precision-Recall Curve (PR-AUC)*. We'll show how to train the model both with (i) plain TensorFlow (in eager mode), and (ii) with a custom tf.Estimator.\n",
        "\n",
        "We start by importing the relevant modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FoYVEXPA_Bdp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "import tensorflow.compat.v2 as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ea1KIDRgC4eq"
      },
      "outputs": [],
      "source": [
        "# Tensorflow constrained optimization library\n",
        "!pip install git+https://github.com/google-research/tensorflow_constrained_optimization\n",
        "import tensorflow_constrained_optimization as tfco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BLxZD5uH_Bds"
      },
      "source": [
        "## Communities and Crimes\n",
        "\n",
        "We will use the  *Communities and Crimes* dataset from the UCI Machine Learning repository for our illustration. This dataset contains various demographic and racial distribution details (aggregated from census and law enforcement data sources) about different communities in the US, along with the per capita crime rate in each commmunity. \n",
        "\n",
        "\n",
        "We begin by downloading and preprocessing the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MgoeyhS0_Bds"
      },
      "outputs": [],
      "source": [
        "# List of column names in the dataset.\n",
        "column_names = [\"state\", \"county\", \"community\", \"communityname\", \"fold\", \"population\", \"householdsize\", \"racepctblack\", \"racePctWhite\", \"racePctAsian\", \"racePctHisp\", \"agePct12t21\", \"agePct12t29\", \"agePct16t24\", \"agePct65up\", \"numbUrban\", \"pctUrban\", \"medIncome\", \"pctWWage\", \"pctWFarmSelf\", \"pctWInvInc\", \"pctWSocSec\", \"pctWPubAsst\", \"pctWRetire\", \"medFamInc\", \"perCapInc\", \"whitePerCap\", \"blackPerCap\", \"indianPerCap\", \"AsianPerCap\", \"OtherPerCap\", \"HispPerCap\", \"NumUnderPov\", \"PctPopUnderPov\", \"PctLess9thGrade\", \"PctNotHSGrad\", \"PctBSorMore\", \"PctUnemployed\", \"PctEmploy\", \"PctEmplManu\", \"PctEmplProfServ\", \"PctOccupManu\", \"PctOccupMgmtProf\", \"MalePctDivorce\", \"MalePctNevMarr\", \"FemalePctDiv\", \"TotalPctDiv\", \"PersPerFam\", \"PctFam2Par\", \"PctKids2Par\", \"PctYoungKids2Par\", \"PctTeen2Par\", \"PctWorkMomYoungKids\", \"PctWorkMom\", \"NumIlleg\", \"PctIlleg\", \"NumImmig\", \"PctImmigRecent\", \"PctImmigRec5\", \"PctImmigRec8\", \"PctImmigRec10\", \"PctRecentImmig\", \"PctRecImmig5\", \"PctRecImmig8\", \"PctRecImmig10\", \"PctSpeakEnglOnly\", \"PctNotSpeakEnglWell\", \"PctLargHouseFam\", \"PctLargHouseOccup\", \"PersPerOccupHous\", \"PersPerOwnOccHous\", \"PersPerRentOccHous\", \"PctPersOwnOccup\", \"PctPersDenseHous\", \"PctHousLess3BR\", \"MedNumBR\", \"HousVacant\", \"PctHousOccup\", \"PctHousOwnOcc\", \"PctVacantBoarded\", \"PctVacMore6Mos\", \"MedYrHousBuilt\", \"PctHousNoPhone\", \"PctWOFullPlumb\", \"OwnOccLowQuart\", \"OwnOccMedVal\", \"OwnOccHiQuart\", \"RentLowQ\", \"RentMedian\", \"RentHighQ\", \"MedRent\", \"MedRentPctHousInc\", \"MedOwnCostPctInc\", \"MedOwnCostPctIncNoMtg\", \"NumInShelters\", \"NumStreet\", \"PctForeignBorn\", \"PctBornSameState\", \"PctSameHouse85\", \"PctSameCity85\", \"PctSameState85\", \"LemasSwornFT\", \"LemasSwFTPerPop\", \"LemasSwFTFieldOps\", \"LemasSwFTFieldPerPop\", \"LemasTotalReq\", \"LemasTotReqPerPop\", \"PolicReqPerOffic\", \"PolicPerPop\", \"RacialMatchCommPol\", \"PctPolicWhite\", \"PctPolicBlack\", \"PctPolicHisp\", \"PctPolicAsian\", \"PctPolicMinor\", \"OfficAssgnDrugUnits\", \"NumKindsDrugsSeiz\", \"PolicAveOTWorked\", \"LandArea\", \"PopDens\", \"PctUsePubTrans\", \"PolicCars\", \"PolicOperBudg\", \"LemasPctPolicOnPatr\", \"LemasGangUnitDeploy\", \"LemasPctOfficDrugUn\", \"PolicBudgPerPop\", \"ViolentCrimesPerPop\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 7296,
          "status": "ok",
          "timestamp": 1586286901394,
          "user": {
            "displayName": "Harikrishna Narasimhan",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjyg52klSoxBSFMtplEnNP91q3WZE0cd4EDc2lJ=s64",
            "userId": "06672706079361346307"
          },
          "user_tz": 420
        },
        "id": "gJ_JcV-V_Bdu",
        "outputId": "156a5dd5-4d11-4c84-df79-18895c47a07a",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border=\"1\" class=\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style=\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003estate\u003c/th\u003e\n",
              "      \u003cth\u003ecounty\u003c/th\u003e\n",
              "      \u003cth\u003ecommunity\u003c/th\u003e\n",
              "      \u003cth\u003ecommunityname\u003c/th\u003e\n",
              "      \u003cth\u003efold\u003c/th\u003e\n",
              "      \u003cth\u003epopulation\u003c/th\u003e\n",
              "      \u003cth\u003ehouseholdsize\u003c/th\u003e\n",
              "      \u003cth\u003eracepctblack\u003c/th\u003e\n",
              "      \u003cth\u003eracePctWhite\u003c/th\u003e\n",
              "      \u003cth\u003eracePctAsian\u003c/th\u003e\n",
              "      \u003cth\u003eracePctHisp\u003c/th\u003e\n",
              "      \u003cth\u003eagePct12t21\u003c/th\u003e\n",
              "      \u003cth\u003eagePct12t29\u003c/th\u003e\n",
              "      \u003cth\u003eagePct16t24\u003c/th\u003e\n",
              "      \u003cth\u003eagePct65up\u003c/th\u003e\n",
              "      \u003cth\u003enumbUrban\u003c/th\u003e\n",
              "      \u003cth\u003epctUrban\u003c/th\u003e\n",
              "      \u003cth\u003emedIncome\u003c/th\u003e\n",
              "      \u003cth\u003epctWWage\u003c/th\u003e\n",
              "      \u003cth\u003epctWFarmSelf\u003c/th\u003e\n",
              "      \u003cth\u003epctWInvInc\u003c/th\u003e\n",
              "      \u003cth\u003epctWSocSec\u003c/th\u003e\n",
              "      \u003cth\u003epctWPubAsst\u003c/th\u003e\n",
              "      \u003cth\u003epctWRetire\u003c/th\u003e\n",
              "      \u003cth\u003emedFamInc\u003c/th\u003e\n",
              "      \u003cth\u003eperCapInc\u003c/th\u003e\n",
              "      \u003cth\u003ewhitePerCap\u003c/th\u003e\n",
              "      \u003cth\u003eblackPerCap\u003c/th\u003e\n",
              "      \u003cth\u003eindianPerCap\u003c/th\u003e\n",
              "      \u003cth\u003eAsianPerCap\u003c/th\u003e\n",
              "      \u003cth\u003eOtherPerCap\u003c/th\u003e\n",
              "      \u003cth\u003eHispPerCap\u003c/th\u003e\n",
              "      \u003cth\u003eNumUnderPov\u003c/th\u003e\n",
              "      \u003cth\u003ePctPopUnderPov\u003c/th\u003e\n",
              "      \u003cth\u003ePctLess9thGrade\u003c/th\u003e\n",
              "      \u003cth\u003ePctNotHSGrad\u003c/th\u003e\n",
              "      \u003cth\u003ePctBSorMore\u003c/th\u003e\n",
              "      \u003cth\u003ePctUnemployed\u003c/th\u003e\n",
              "      \u003cth\u003ePctEmploy\u003c/th\u003e\n",
              "      \u003cth\u003ePctEmplManu\u003c/th\u003e\n",
              "      \u003cth\u003e...\u003c/th\u003e\n",
              "      \u003cth\u003eRentMedian\u003c/th\u003e\n",
              "      \u003cth\u003eRentHighQ\u003c/th\u003e\n",
              "      \u003cth\u003eMedRent\u003c/th\u003e\n",
              "      \u003cth\u003eMedRentPctHousInc\u003c/th\u003e\n",
              "      \u003cth\u003eMedOwnCostPctInc\u003c/th\u003e\n",
              "      \u003cth\u003eMedOwnCostPctIncNoMtg\u003c/th\u003e\n",
              "      \u003cth\u003eNumInShelters\u003c/th\u003e\n",
              "      \u003cth\u003eNumStreet\u003c/th\u003e\n",
              "      \u003cth\u003ePctForeignBorn\u003c/th\u003e\n",
              "      \u003cth\u003ePctBornSameState\u003c/th\u003e\n",
              "      \u003cth\u003ePctSameHouse85\u003c/th\u003e\n",
              "      \u003cth\u003ePctSameCity85\u003c/th\u003e\n",
              "      \u003cth\u003ePctSameState85\u003c/th\u003e\n",
              "      \u003cth\u003eLemasSwornFT\u003c/th\u003e\n",
              "      \u003cth\u003eLemasSwFTPerPop\u003c/th\u003e\n",
              "      \u003cth\u003eLemasSwFTFieldOps\u003c/th\u003e\n",
              "      \u003cth\u003eLemasSwFTFieldPerPop\u003c/th\u003e\n",
              "      \u003cth\u003eLemasTotalReq\u003c/th\u003e\n",
              "      \u003cth\u003eLemasTotReqPerPop\u003c/th\u003e\n",
              "      \u003cth\u003ePolicReqPerOffic\u003c/th\u003e\n",
              "      \u003cth\u003ePolicPerPop\u003c/th\u003e\n",
              "      \u003cth\u003eRacialMatchCommPol\u003c/th\u003e\n",
              "      \u003cth\u003ePctPolicWhite\u003c/th\u003e\n",
              "      \u003cth\u003ePctPolicBlack\u003c/th\u003e\n",
              "      \u003cth\u003ePctPolicHisp\u003c/th\u003e\n",
              "      \u003cth\u003ePctPolicAsian\u003c/th\u003e\n",
              "      \u003cth\u003ePctPolicMinor\u003c/th\u003e\n",
              "      \u003cth\u003eOfficAssgnDrugUnits\u003c/th\u003e\n",
              "      \u003cth\u003eNumKindsDrugsSeiz\u003c/th\u003e\n",
              "      \u003cth\u003ePolicAveOTWorked\u003c/th\u003e\n",
              "      \u003cth\u003eLandArea\u003c/th\u003e\n",
              "      \u003cth\u003ePopDens\u003c/th\u003e\n",
              "      \u003cth\u003ePctUsePubTrans\u003c/th\u003e\n",
              "      \u003cth\u003ePolicCars\u003c/th\u003e\n",
              "      \u003cth\u003ePolicOperBudg\u003c/th\u003e\n",
              "      \u003cth\u003eLemasPctPolicOnPatr\u003c/th\u003e\n",
              "      \u003cth\u003eLemasGangUnitDeploy\u003c/th\u003e\n",
              "      \u003cth\u003eLemasPctOfficDrugUn\u003c/th\u003e\n",
              "      \u003cth\u003ePolicBudgPerPop\u003c/th\u003e\n",
              "      \u003cth\u003eViolentCrimesPerPop\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003ctd\u003e8\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eLakewoodcity\u003c/td\u003e\n",
              "      \u003ctd\u003e1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.19\u003c/td\u003e\n",
              "      \u003ctd\u003e0.33\u003c/td\u003e\n",
              "      \u003ctd\u003e0.02\u003c/td\u003e\n",
              "      \u003ctd\u003e0.90\u003c/td\u003e\n",
              "      \u003ctd\u003e0.12\u003c/td\u003e\n",
              "      \u003ctd\u003e0.17\u003c/td\u003e\n",
              "      \u003ctd\u003e0.34\u003c/td\u003e\n",
              "      \u003ctd\u003e0.47\u003c/td\u003e\n",
              "      \u003ctd\u003e0.29\u003c/td\u003e\n",
              "      \u003ctd\u003e0.32\u003c/td\u003e\n",
              "      \u003ctd\u003e0.20\u003c/td\u003e\n",
              "      \u003ctd\u003e1.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.37\u003c/td\u003e\n",
              "      \u003ctd\u003e0.72\u003c/td\u003e\n",
              "      \u003ctd\u003e0.34\u003c/td\u003e\n",
              "      \u003ctd\u003e0.60\u003c/td\u003e\n",
              "      \u003ctd\u003e0.29\u003c/td\u003e\n",
              "      \u003ctd\u003e0.15\u003c/td\u003e\n",
              "      \u003ctd\u003e0.43\u003c/td\u003e\n",
              "      \u003ctd\u003e0.39\u003c/td\u003e\n",
              "      \u003ctd\u003e0.40\u003c/td\u003e\n",
              "      \u003ctd\u003e0.39\u003c/td\u003e\n",
              "      \u003ctd\u003e0.32\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.36\u003c/td\u003e\n",
              "      \u003ctd\u003e0.41\u003c/td\u003e\n",
              "      \u003ctd\u003e0.08\u003c/td\u003e\n",
              "      \u003ctd\u003e0.19\u003c/td\u003e\n",
              "      \u003ctd\u003e0.10\u003c/td\u003e\n",
              "      \u003ctd\u003e0.18\u003c/td\u003e\n",
              "      \u003ctd\u003e0.48\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.68\u003c/td\u003e\n",
              "      \u003ctd\u003e0.23\u003c/td\u003e\n",
              "      \u003ctd\u003e...\u003c/td\u003e\n",
              "      \u003ctd\u003e0.35\u003c/td\u003e\n",
              "      \u003ctd\u003e0.38\u003c/td\u003e\n",
              "      \u003ctd\u003e0.34\u003c/td\u003e\n",
              "      \u003ctd\u003e0.38\u003c/td\u003e\n",
              "      \u003ctd\u003e0.46\u003c/td\u003e\n",
              "      \u003ctd\u003e0.25\u003c/td\u003e\n",
              "      \u003ctd\u003e0.04\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.12\u003c/td\u003e\n",
              "      \u003ctd\u003e0.42\u003c/td\u003e\n",
              "      \u003ctd\u003e0.50\u003c/td\u003e\n",
              "      \u003ctd\u003e0.51\u003c/td\u003e\n",
              "      \u003ctd\u003e0.64\u003c/td\u003e\n",
              "      \u003ctd\u003e0.03\u003c/td\u003e\n",
              "      \u003ctd\u003e0.13\u003c/td\u003e\n",
              "      \u003ctd\u003e0.96\u003c/td\u003e\n",
              "      \u003ctd\u003e0.17\u003c/td\u003e\n",
              "      \u003ctd\u003e0.06\u003c/td\u003e\n",
              "      \u003ctd\u003e0.18\u003c/td\u003e\n",
              "      \u003ctd\u003e0.44\u003c/td\u003e\n",
              "      \u003ctd\u003e0.13\u003c/td\u003e\n",
              "      \u003ctd\u003e0.94\u003c/td\u003e\n",
              "      \u003ctd\u003e0.93\u003c/td\u003e\n",
              "      \u003ctd\u003e0.03\u003c/td\u003e\n",
              "      \u003ctd\u003e0.07\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.07\u003c/td\u003e\n",
              "      \u003ctd\u003e0.02\u003c/td\u003e\n",
              "      \u003ctd\u003e0.57\u003c/td\u003e\n",
              "      \u003ctd\u003e0.29\u003c/td\u003e\n",
              "      \u003ctd\u003e0.12\u003c/td\u003e\n",
              "      \u003ctd\u003e0.26\u003c/td\u003e\n",
              "      \u003ctd\u003e0.20\u003c/td\u003e\n",
              "      \u003ctd\u003e0.06\u003c/td\u003e\n",
              "      \u003ctd\u003e0.04\u003c/td\u003e\n",
              "      \u003ctd\u003e0.9\u003c/td\u003e\n",
              "      \u003ctd\u003e0.5\u003c/td\u003e\n",
              "      \u003ctd\u003e0.32\u003c/td\u003e\n",
              "      \u003ctd\u003e0.14\u003c/td\u003e\n",
              "      \u003ctd\u003e0.20\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003ctd\u003e53\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eTukwilacity\u003c/td\u003e\n",
              "      \u003ctd\u003e1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.16\u003c/td\u003e\n",
              "      \u003ctd\u003e0.12\u003c/td\u003e\n",
              "      \u003ctd\u003e0.74\u003c/td\u003e\n",
              "      \u003ctd\u003e0.45\u003c/td\u003e\n",
              "      \u003ctd\u003e0.07\u003c/td\u003e\n",
              "      \u003ctd\u003e0.26\u003c/td\u003e\n",
              "      \u003ctd\u003e0.59\u003c/td\u003e\n",
              "      \u003ctd\u003e0.35\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.02\u003c/td\u003e\n",
              "      \u003ctd\u003e1.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.31\u003c/td\u003e\n",
              "      \u003ctd\u003e0.72\u003c/td\u003e\n",
              "      \u003ctd\u003e0.11\u003c/td\u003e\n",
              "      \u003ctd\u003e0.45\u003c/td\u003e\n",
              "      \u003ctd\u003e0.25\u003c/td\u003e\n",
              "      \u003ctd\u003e0.29\u003c/td\u003e\n",
              "      \u003ctd\u003e0.39\u003c/td\u003e\n",
              "      \u003ctd\u003e0.29\u003c/td\u003e\n",
              "      \u003ctd\u003e0.37\u003c/td\u003e\n",
              "      \u003ctd\u003e0.38\u003c/td\u003e\n",
              "      \u003ctd\u003e0.33\u003c/td\u003e\n",
              "      \u003ctd\u003e0.16\u003c/td\u003e\n",
              "      \u003ctd\u003e0.30\u003c/td\u003e\n",
              "      \u003ctd\u003e0.22\u003c/td\u003e\n",
              "      \u003ctd\u003e0.35\u003c/td\u003e\n",
              "      \u003ctd\u003e0.01\u003c/td\u003e\n",
              "      \u003ctd\u003e0.24\u003c/td\u003e\n",
              "      \u003ctd\u003e0.14\u003c/td\u003e\n",
              "      \u003ctd\u003e0.24\u003c/td\u003e\n",
              "      \u003ctd\u003e0.30\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.73\u003c/td\u003e\n",
              "      \u003ctd\u003e0.57\u003c/td\u003e\n",
              "      \u003ctd\u003e...\u003c/td\u003e\n",
              "      \u003ctd\u003e0.38\u003c/td\u003e\n",
              "      \u003ctd\u003e0.40\u003c/td\u003e\n",
              "      \u003ctd\u003e0.37\u003c/td\u003e\n",
              "      \u003ctd\u003e0.29\u003c/td\u003e\n",
              "      \u003ctd\u003e0.32\u003c/td\u003e\n",
              "      \u003ctd\u003e0.18\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.21\u003c/td\u003e\n",
              "      \u003ctd\u003e0.50\u003c/td\u003e\n",
              "      \u003ctd\u003e0.34\u003c/td\u003e\n",
              "      \u003ctd\u003e0.60\u003c/td\u003e\n",
              "      \u003ctd\u003e0.52\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.02\u003c/td\u003e\n",
              "      \u003ctd\u003e0.12\u003c/td\u003e\n",
              "      \u003ctd\u003e0.45\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.67\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e2\u003c/th\u003e\n",
              "      \u003ctd\u003e24\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eAberdeentown\u003c/td\u003e\n",
              "      \u003ctd\u003e1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.42\u003c/td\u003e\n",
              "      \u003ctd\u003e0.49\u003c/td\u003e\n",
              "      \u003ctd\u003e0.56\u003c/td\u003e\n",
              "      \u003ctd\u003e0.17\u003c/td\u003e\n",
              "      \u003ctd\u003e0.04\u003c/td\u003e\n",
              "      \u003ctd\u003e0.39\u003c/td\u003e\n",
              "      \u003ctd\u003e0.47\u003c/td\u003e\n",
              "      \u003ctd\u003e0.28\u003c/td\u003e\n",
              "      \u003ctd\u003e0.32\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.30\u003c/td\u003e\n",
              "      \u003ctd\u003e0.58\u003c/td\u003e\n",
              "      \u003ctd\u003e0.19\u003c/td\u003e\n",
              "      \u003ctd\u003e0.39\u003c/td\u003e\n",
              "      \u003ctd\u003e0.38\u003c/td\u003e\n",
              "      \u003ctd\u003e0.40\u003c/td\u003e\n",
              "      \u003ctd\u003e0.84\u003c/td\u003e\n",
              "      \u003ctd\u003e0.28\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.29\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.07\u003c/td\u003e\n",
              "      \u003ctd\u003e0.29\u003c/td\u003e\n",
              "      \u003ctd\u003e0.28\u003c/td\u003e\n",
              "      \u003ctd\u003e0.39\u003c/td\u003e\n",
              "      \u003ctd\u003e0.01\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.43\u003c/td\u003e\n",
              "      \u003ctd\u003e0.19\u003c/td\u003e\n",
              "      \u003ctd\u003e0.36\u003c/td\u003e\n",
              "      \u003ctd\u003e0.58\u003c/td\u003e\n",
              "      \u003ctd\u003e0.32\u003c/td\u003e\n",
              "      \u003ctd\u003e...\u003c/td\u003e\n",
              "      \u003ctd\u003e0.29\u003c/td\u003e\n",
              "      \u003ctd\u003e0.27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.31\u003c/td\u003e\n",
              "      \u003ctd\u003e0.48\u003c/td\u003e\n",
              "      \u003ctd\u003e0.39\u003c/td\u003e\n",
              "      \u003ctd\u003e0.28\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.14\u003c/td\u003e\n",
              "      \u003ctd\u003e0.49\u003c/td\u003e\n",
              "      \u003ctd\u003e0.54\u003c/td\u003e\n",
              "      \u003ctd\u003e0.67\u003c/td\u003e\n",
              "      \u003ctd\u003e0.56\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.01\u003c/td\u003e\n",
              "      \u003ctd\u003e0.21\u003c/td\u003e\n",
              "      \u003ctd\u003e0.02\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.43\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e3\u003c/th\u003e\n",
              "      \u003ctd\u003e34\u003c/td\u003e\n",
              "      \u003ctd\u003e5.0\u003c/td\u003e\n",
              "      \u003ctd\u003e81440.0\u003c/td\u003e\n",
              "      \u003ctd\u003eWillingborotownship\u003c/td\u003e\n",
              "      \u003ctd\u003e1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.04\u003c/td\u003e\n",
              "      \u003ctd\u003e0.77\u003c/td\u003e\n",
              "      \u003ctd\u003e1.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.08\u003c/td\u003e\n",
              "      \u003ctd\u003e0.12\u003c/td\u003e\n",
              "      \u003ctd\u003e0.10\u003c/td\u003e\n",
              "      \u003ctd\u003e0.51\u003c/td\u003e\n",
              "      \u003ctd\u003e0.50\u003c/td\u003e\n",
              "      \u003ctd\u003e0.34\u003c/td\u003e\n",
              "      \u003ctd\u003e0.21\u003c/td\u003e\n",
              "      \u003ctd\u003e0.06\u003c/td\u003e\n",
              "      \u003ctd\u003e1.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.58\u003c/td\u003e\n",
              "      \u003ctd\u003e0.89\u003c/td\u003e\n",
              "      \u003ctd\u003e0.21\u003c/td\u003e\n",
              "      \u003ctd\u003e0.43\u003c/td\u003e\n",
              "      \u003ctd\u003e0.36\u003c/td\u003e\n",
              "      \u003ctd\u003e0.20\u003c/td\u003e\n",
              "      \u003ctd\u003e0.82\u003c/td\u003e\n",
              "      \u003ctd\u003e0.51\u003c/td\u003e\n",
              "      \u003ctd\u003e0.36\u003c/td\u003e\n",
              "      \u003ctd\u003e0.40\u003c/td\u003e\n",
              "      \u003ctd\u003e0.39\u003c/td\u003e\n",
              "      \u003ctd\u003e0.16\u003c/td\u003e\n",
              "      \u003ctd\u003e0.25\u003c/td\u003e\n",
              "      \u003ctd\u003e0.36\u003c/td\u003e\n",
              "      \u003ctd\u003e0.44\u003c/td\u003e\n",
              "      \u003ctd\u003e0.01\u003c/td\u003e\n",
              "      \u003ctd\u003e0.10\u003c/td\u003e\n",
              "      \u003ctd\u003e0.09\u003c/td\u003e\n",
              "      \u003ctd\u003e0.25\u003c/td\u003e\n",
              "      \u003ctd\u003e0.31\u003c/td\u003e\n",
              "      \u003ctd\u003e0.33\u003c/td\u003e\n",
              "      \u003ctd\u003e0.71\u003c/td\u003e\n",
              "      \u003ctd\u003e0.36\u003c/td\u003e\n",
              "      \u003ctd\u003e...\u003c/td\u003e\n",
              "      \u003ctd\u003e0.70\u003c/td\u003e\n",
              "      \u003ctd\u003e0.77\u003c/td\u003e\n",
              "      \u003ctd\u003e0.89\u003c/td\u003e\n",
              "      \u003ctd\u003e0.63\u003c/td\u003e\n",
              "      \u003ctd\u003e0.51\u003c/td\u003e\n",
              "      \u003ctd\u003e0.47\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.19\u003c/td\u003e\n",
              "      \u003ctd\u003e0.30\u003c/td\u003e\n",
              "      \u003ctd\u003e0.73\u003c/td\u003e\n",
              "      \u003ctd\u003e0.64\u003c/td\u003e\n",
              "      \u003ctd\u003e0.65\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.02\u003c/td\u003e\n",
              "      \u003ctd\u003e0.39\u003c/td\u003e\n",
              "      \u003ctd\u003e0.28\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.12\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e4\u003c/th\u003e\n",
              "      \u003ctd\u003e42\u003c/td\u003e\n",
              "      \u003ctd\u003e95.0\u003c/td\u003e\n",
              "      \u003ctd\u003e6096.0\u003c/td\u003e\n",
              "      \u003ctd\u003eBethlehemtownship\u003c/td\u003e\n",
              "      \u003ctd\u003e1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.01\u003c/td\u003e\n",
              "      \u003ctd\u003e0.55\u003c/td\u003e\n",
              "      \u003ctd\u003e0.02\u003c/td\u003e\n",
              "      \u003ctd\u003e0.95\u003c/td\u003e\n",
              "      \u003ctd\u003e0.09\u003c/td\u003e\n",
              "      \u003ctd\u003e0.05\u003c/td\u003e\n",
              "      \u003ctd\u003e0.38\u003c/td\u003e\n",
              "      \u003ctd\u003e0.38\u003c/td\u003e\n",
              "      \u003ctd\u003e0.23\u003c/td\u003e\n",
              "      \u003ctd\u003e0.36\u003c/td\u003e\n",
              "      \u003ctd\u003e0.02\u003c/td\u003e\n",
              "      \u003ctd\u003e0.9\u003c/td\u003e\n",
              "      \u003ctd\u003e0.50\u003c/td\u003e\n",
              "      \u003ctd\u003e0.72\u003c/td\u003e\n",
              "      \u003ctd\u003e0.16\u003c/td\u003e\n",
              "      \u003ctd\u003e0.68\u003c/td\u003e\n",
              "      \u003ctd\u003e0.44\u003c/td\u003e\n",
              "      \u003ctd\u003e0.11\u003c/td\u003e\n",
              "      \u003ctd\u003e0.71\u003c/td\u003e\n",
              "      \u003ctd\u003e0.46\u003c/td\u003e\n",
              "      \u003ctd\u003e0.43\u003c/td\u003e\n",
              "      \u003ctd\u003e0.41\u003c/td\u003e\n",
              "      \u003ctd\u003e0.28\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.74\u003c/td\u003e\n",
              "      \u003ctd\u003e0.51\u003c/td\u003e\n",
              "      \u003ctd\u003e0.48\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.06\u003c/td\u003e\n",
              "      \u003ctd\u003e0.25\u003c/td\u003e\n",
              "      \u003ctd\u003e0.30\u003c/td\u003e\n",
              "      \u003ctd\u003e0.33\u003c/td\u003e\n",
              "      \u003ctd\u003e0.12\u003c/td\u003e\n",
              "      \u003ctd\u003e0.65\u003c/td\u003e\n",
              "      \u003ctd\u003e0.67\u003c/td\u003e\n",
              "      \u003ctd\u003e...\u003c/td\u003e\n",
              "      \u003ctd\u003e0.36\u003c/td\u003e\n",
              "      \u003ctd\u003e0.38\u003c/td\u003e\n",
              "      \u003ctd\u003e0.38\u003c/td\u003e\n",
              "      \u003ctd\u003e0.22\u003c/td\u003e\n",
              "      \u003ctd\u003e0.51\u003c/td\u003e\n",
              "      \u003ctd\u003e0.21\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.11\u003c/td\u003e\n",
              "      \u003ctd\u003e0.72\u003c/td\u003e\n",
              "      \u003ctd\u003e0.64\u003c/td\u003e\n",
              "      \u003ctd\u003e0.61\u003c/td\u003e\n",
              "      \u003ctd\u003e0.53\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.04\u003c/td\u003e\n",
              "      \u003ctd\u003e0.09\u003c/td\u003e\n",
              "      \u003ctd\u003e0.02\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.00\u003c/td\u003e\n",
              "      \u003ctd\u003eNaN\u003c/td\u003e\n",
              "      \u003ctd\u003e0.03\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003cp\u003e5 rows Ã— 128 columns\u003c/p\u003e\n",
              "\u003c/div\u003e"
            ],
            "text/plain": [
              "   state  county  ...  PolicBudgPerPop ViolentCrimesPerPop\n",
              "0      8     NaN  ...             0.14                0.20\n",
              "1     53     NaN  ...              NaN                0.67\n",
              "2     24     NaN  ...              NaN                0.43\n",
              "3     34     5.0  ...              NaN                0.12\n",
              "4     42    95.0  ...              NaN                0.03\n",
              "\n",
              "[5 rows x 128 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data\"\n",
        "\n",
        "# Read dataset from the UCI web repository and assign column names.\n",
        "data_df = pd.read_csv(dataset_url, sep=\",\", names=column_names,\n",
        "                      na_values=\"?\")\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MWHnYDmL_Bdx"
      },
      "source": [
        "The 'ViolentCrimesPerPop' column contains the per capita crime rate for each community. We label the communities with a crime rate above the 70-th percentile as 'high crime' and the others as 'low crime'. These would serve as our binary target labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fJtOkt90_Bdy"
      },
      "outputs": [],
      "source": [
        "# Make sure there are no missing values in the \"ViolentCrimesPerPop\" column.\n",
        "assert(not data_df[\"ViolentCrimesPerPop\"].isna().any())\n",
        "\n",
        "# Binarize the \"ViolentCrimesPerPop\" column and obtain labels.\n",
        "crime_rate_70_percentile = data_df[\"ViolentCrimesPerPop\"].quantile(q=0.7)\n",
        "labels_df = (data_df[\"ViolentCrimesPerPop\"] \u003e= crime_rate_70_percentile)\n",
        "\n",
        "# Now that we have assigned binary labels, \n",
        "# we drop the \"ViolentCrimesPerPop\" column from the data frame.\n",
        "data_df.drop(columns=\"ViolentCrimesPerPop\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n8-rQaGH_Bd2"
      },
      "source": [
        "We drop all categorical columns, and use only the numerical/boolean features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WC12I50e_Bd3"
      },
      "outputs": [],
      "source": [
        "data_df.drop(columns=[\"state\", \"county\", \"community\", \"communityname\", \"fold\"],\n",
        "             inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2eJcNA1B_Bd5"
      },
      "source": [
        "Some of the numerical columns contain missing values (denoted by a NaN). For each feature that has at least one value missing, we append an additional boolean \"is_missing\" feature indicating that the value was missing, and fill the missing value with 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8_RgukXn_Bd5"
      },
      "outputs": [],
      "source": [
        "feature_names = data_df.columns\n",
        "for feature_name in feature_names:  \n",
        "    # Which rows have missing values?\n",
        "    missing_rows = data_df[feature_name].isna()\n",
        "    if missing_rows.any():  # Check if at least one row has a missing value.\n",
        "        data_df[feature_name].fillna(0.0, inplace=True)  # Fill NaN with 0.\n",
        "        missing_rows.rename(feature_name + \"_is_missing\", inplace=True)\n",
        "        data_df = data_df.join(missing_rows)  # Append \"is_missing\" feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S8U5yENt_Bd-"
      },
      "source": [
        "Finally, we divide the dataset randomly into two-thirds for training and one-thirds for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bixDM2G0Bspg"
      },
      "outputs": [],
      "source": [
        "# Set random seed so that the results are reproducible.\n",
        "np.random.seed(123456)\n",
        "\n",
        "# Train and test indices.\n",
        "train_indices, test_indices = model_selection.train_test_split(\n",
        "    np.arange(data_df.shape[0]), test_size=1./3.)\n",
        "\n",
        "# Train and test data.\n",
        "x_train_df = data_df.loc[train_indices].astype(np.float32)\n",
        "y_train_df = labels_df.loc[train_indices].astype(np.float32)\n",
        "x_test_df = data_df.loc[test_indices].astype(np.float32)\n",
        "y_test_df = labels_df.loc[test_indices].astype(np.float32)\n",
        "\n",
        "# Convert data frames to NumPy arrays.\n",
        "x_train = x_train_df.values\n",
        "y_train = y_train_df.values\n",
        "x_test = x_test_df.values\n",
        "y_test = y_test_df.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gXyyoSrG_BeA"
      },
      "source": [
        "## (i) PR-AUC Training with Plain TF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hoqCCpf0oTIY"
      },
      "outputs": [],
      "source": [
        "batch_size = 128  # first fix the batch size for mini-batch training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wqo2mpRi_BeA"
      },
      "source": [
        "\n",
        "We will work with a linear classification model and define the data and model tensors. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "i1fxMQmy_BeB"
      },
      "outputs": [],
      "source": [
        "# Create linear Keras model.\n",
        "layers = []\n",
        "layers.append(tf.keras.Input(shape=(x_train.shape[-1],)))\n",
        "layers.append(tf.keras.layers.Dense(1))\n",
        "model = tf.keras.Sequential(layers)\n",
        "\n",
        "# Create nullary functions that return labels and logits from the current\n",
        "# batch. In eager mode, TFCO requires these to be provided via nullary function.\n",
        "# We will maintain a running array of batch indices.\n",
        "batch_indices = np.arange(batch_size)\n",
        "labels_fn = lambda: tf.constant(y_train[batch_indices], dtype=tf.float32)\n",
        "logits_fn = lambda: model(x_train[batch_indices, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gmFBVhsQ_BeD"
      },
      "source": [
        "We next set up the constraint optimization problem to optimize PR-AUC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8Swn_y0T_BeD"
      },
      "outputs": [],
      "source": [
        "# Create context with labels and predictions.\n",
        "context = tfco.rate_context(logits_fn, labels_fn)\n",
        "\n",
        "# Create optimization problem with PR-AUC as the objective. The library\n",
        "# expects a minimization objective, so we negate the PR-AUC. \n",
        "\n",
        "# We use the pr_auc rate helper which uses a Riemann approximation to the area \n",
        "# under the precision-recall curve (recall on the horizontal axis, precision on \n",
        "# the vertical axis). We would need to specify the the number of bins \n",
        "# (\"rectangles\") to use for the Riemann approximation. We also can optionally\n",
        "# specify the surrogate to be used to approximate the PR-AUC.\n",
        "pr_auc_rate = tfco.pr_auc(\n",
        "    context, bins=10, penalty_loss=tfco.SoftmaxCrossEntropyLoss())\n",
        "problem = tfco.RateMinimizationProblem(-pr_auc_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OwpTHgqg_BeG"
      },
      "source": [
        "We then create a loss function from the `problem` and optimize it to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nkq2aVIn_BeG"
      },
      "outputs": [],
      "source": [
        "# Create Lagrangian loss for `problem`. What we get back is a loss function, a \n",
        "# a nullary function that returns a list of update_ops that need to be run \n",
        "# before every gradient update, and the Lagrange multiplier variables internally\n",
        "# maintained by the loss function. The argument `dual_scale` is a \n",
        "# hyper-parameter that specifies the relative importance placed on updates on \n",
        "# the Lagrange multipliers.\n",
        "loss_fn, update_ops_fn, multipliers = tfco.create_lagrangian_loss(\n",
        "    problem, dual_scale=1.0)\n",
        "\n",
        "# Set up optimizer and the list of variables to optimize.\n",
        "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
        "var_list = (model.trainable_weights + problem.trainable_variables + \n",
        "            [multipliers])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ra-Cog9C_BeI"
      },
      "source": [
        "Before proceeding to solving the training problem, we write an evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gFUyqbVx_BeI"
      },
      "outputs": [],
      "source": [
        "def pr_auc(model, features, labels):\n",
        "    # Returns the PR-AUC for given model, features and binary labels.\n",
        "    scores = model.predict(features)\n",
        "    return metrics.average_precision_score(labels, scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MID6ChJn_BeK"
      },
      "source": [
        "We are now ready to train our model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 32408,
          "status": "ok",
          "timestamp": 1586287165652,
          "user": {
            "displayName": "Harikrishna Narasimhan",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjyg52klSoxBSFMtplEnNP91q3WZE0cd4EDc2lJ=s64",
            "userId": "06672706079361346307"
          },
          "user_tz": 420
        },
        "id": "ZWUWtSp8NzK5",
        "outputId": "34f92500-35c7-408f-d4dc-9c845d9d23c6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAD0CAYAAACGlm89AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxsndzMysYJzczczMCub/A/HXbJVyEMq1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "\u003cFigure size 504x252 with 2 Axes\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_steps = 250\n",
        "num_examples = x_train.shape[0]\n",
        "\n",
        "train_objectives = []\n",
        "test_objectives = []\n",
        "\n",
        "for ii in range(num_steps):\n",
        "  # Indices for current batch; cycle back once we reach the end of stream.\n",
        "  batch_indices = np.arange(ii * batch_size, (ii + 1) * batch_size)\n",
        "  batch_indices = [ind % num_examples for ind in batch_indices]\n",
        "\n",
        "  # First run update ops, and then gradient update.\n",
        "  update_ops_fn()\n",
        "  optimizer.minimize(loss_fn, var_list=var_list)\n",
        "\n",
        "  # Record train and test objectives once every 10 steps.\n",
        "  if ii % 10 == 0:\n",
        "    train_objectives.append(pr_auc(model, x_train, y_train))\n",
        "    test_objectives.append(pr_auc(model, x_test, y_test))\n",
        "\n",
        "# Plot training and test objective as a function of steps.\n",
        "fig, ax = plt.subplots(1, 2, figsize=(7, 3.5))\n",
        "ax[0].plot(np.arange(1, num_steps + 1, 10), train_objectives)\n",
        "ax[0].set_title('Train PR-AUC')\n",
        "ax[0].set_xlabel('Steps')\n",
        "ax[1].plot(np.arange(1, num_steps + 1, 10), test_objectives)\n",
        "ax[1].set_title('Test PR-AUC')\n",
        "ax[1].set_xlabel('Steps')\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BTGOcqe0pO5a"
      },
      "source": [
        "# (ii) PR-AUC Training with Custom Estimators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uppYKix2-SdA"
      },
      "source": [
        "We next show how one can use TFCO to optimize PR-AUC using custom tf.Estimators.\n",
        "\n",
        "We first create `feature_columns` to convert the dataset into a format that can be processed by an estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_klY8Dqueag_"
      },
      "outputs": [],
      "source": [
        "feature_columns = []\n",
        "for feature_name in x_train_df.columns:\n",
        "  feature_columns.append(\n",
        "      tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jyaRvuOXAGt-"
      },
      "source": [
        "We next construct the input functions that return the data to be used by the estimator for training/evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HoEGUpg9pTdD"
      },
      "outputs": [],
      "source": [
        "def make_input_fn(\n",
        "    data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_fn():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_fn\n",
        "\n",
        "train_input_fn = make_input_fn(x_train_df, y_train_df, num_epochs=25)\n",
        "test_input_fn = make_input_fn(x_test_df, y_test_df, num_epochs=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QSw7IHgKA5NC"
      },
      "source": [
        "We then write the model function that is used by the estimator to create the model, loss, optimizers and metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fUD8PAddptO7"
      },
      "outputs": [],
      "source": [
        "def make_model_fn(feature_columns):\n",
        "  # Returns model_fn.\n",
        "\n",
        "  def model_fn(features, labels, mode):\n",
        "    # Create model from features.\n",
        "    layers = []\n",
        "    layers.append(tf.keras.layers.DenseFeatures(feature_columns))\n",
        "    layers.append(tf.keras.layers.Dense(1))\n",
        "    model = tf.keras.Sequential(layers)\n",
        "    logits = model(features)\n",
        "\n",
        "    # Baseline cross-entropy loss.\n",
        "    baseline_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    baseline_loss = baseline_loss_fn(labels, logits)\n",
        "\n",
        "    # As a slight variant from the above previous training, we will optimize a \n",
        "    # weighted combination of PR-AUC and the baseline loss.\n",
        "    baseline_coef = 0.2\n",
        "    \n",
        "    train_op = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      # Set up PR-AUC optimization problem.\n",
        "      # Create context with labels and predictions.\n",
        "      context = tfco.rate_context(logits, labels)\n",
        "\n",
        "      # Create optimization problem with PR-AUC as the objective. The library\n",
        "      # expects a minimization objective, so we negate the PR-AUC. We optimize\n",
        "      # a convex combination of (negative) PR-AUC and the baseline loss (wrapped\n",
        "      # in a rate object).\n",
        "      pr_auc_rate = tfco.pr_auc(\n",
        "          context, bins=10, penalty_loss=tfco.SoftmaxCrossEntropyLoss())\n",
        "      problem = tfco.RateMinimizationProblem(\n",
        "          (1 - baseline_coef) * (-pr_auc_rate) + \n",
        "          baseline_coef * tfco.wrap_rate(baseline_loss))\n",
        "\n",
        "      # Create Lagrangian loss for `problem`. What we get back is a loss \n",
        "      # function, a nullary function that returns a list of update_ops that \n",
        "      # need to be run before every gradient update, and the Lagrange \n",
        "      # multipliers maintained internally by the loss.\n",
        "      # The argument `dual_scale` is a hyper-parameter that specifies the  \n",
        "      # relative importance placed on updates on the Lagrange multipliers.\n",
        "      loss_fn, update_ops_fn, multipliers = tfco.create_lagrangian_loss(\n",
        "          problem, dual_scale=1.0)\n",
        "      \n",
        "      # Set up optimizer and the list of variables to optimize the loss.\n",
        "      optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
        "      optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\n",
        "      \n",
        "      # Get minimize op and group with update_ops.\n",
        "      var_list = (\n",
        "          model.trainable_weights + problem.trainable_variables + [multipliers])\n",
        "      minimize_op = optimizer.get_updates(loss_fn(), var_list)\n",
        "      update_ops = update_ops_fn()\n",
        "      train_op = tf.group(*update_ops, minimize_op)\n",
        "\n",
        "    # Evaluate PR-AUC.\n",
        "    pr_auc_metric = tf.keras.metrics.AUC(curve='PR')\n",
        "    pr_auc_metric.update_state(labels, tf.sigmoid(logits))\n",
        "\n",
        "    # We do not use the Lagrangian loss for evaluation/bookkeeping\n",
        "    # purposes as it depends on some internal variables that may not be\n",
        "    # set properly during evaluation time. We instead pass loss=baseline_loss.\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode, \n",
        "        predictions=logits, \n",
        "        loss=baseline_loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops={'PR-AUC': pr_auc_metric})\n",
        "    \n",
        "  return model_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4kc3_ftIBC6Y"
      },
      "source": [
        "We are now ready to train the estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 50255,
          "status": "ok",
          "timestamp": 1586286944455,
          "user": {
            "displayName": "Harikrishna Narasimhan",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjyg52klSoxBSFMtplEnNP91q3WZE0cd4EDc2lJ=s64",
            "userId": "06672706079361346307"
          },
          "user_tz": 420
        },
        "id": "TImVz7WMp-Nb",
        "outputId": "c0821891-d991-4a6c-f0f2-37f5a680c74a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'tmp/tfco_206861', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:106: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into tmp/tfco_206861/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.89675474, step = 0\n",
            "INFO:tensorflow:global_step/sec: 57.4359\n",
            "INFO:tensorflow:loss = 0.34256405, step = 100 (1.743 sec)\n",
            "INFO:tensorflow:global_step/sec: 208.997\n",
            "INFO:tensorflow:loss = 0.3015527, step = 200 (0.478 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 250...\n",
            "INFO:tensorflow:Saving checkpoints for 250 into tmp/tfco_206861/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 250...\n",
            "INFO:tensorflow:Loss for final step: 0.45285583.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ctensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7f7d90e67b70\u003e"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a temporary model directory.\n",
        "model_dir = \"tfco_tmp\"\n",
        "if os.path.exists(model_dir):\n",
        "  shutil.rmtree(model_dir)\n",
        "\n",
        "# Train estimator.\n",
        "estimator_lin = tf.estimator.Estimator(\n",
        "    make_model_fn(feature_columns), model_dir=model_dir)\n",
        "estimator_lin.train(train_input_fn, steps=250) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iYkWYCgvBGJA"
      },
      "source": [
        "Finally, we evaluate the trained model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 51788,
          "status": "ok",
          "timestamp": 1586286945996,
          "user": {
            "displayName": "Harikrishna Narasimhan",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjyg52klSoxBSFMtplEnNP91q3WZE0cd4EDc2lJ=s64",
            "userId": "06672706079361346307"
          },
          "user_tz": 420
        },
        "id": "iiB6oG2fqC7S",
        "outputId": "37e10329-8954-4a8c-d26b-cf24a3349a7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-04-07T19:15:44Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from tmp/tfco_206861/model.ckpt-250\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.57194s\n",
            "INFO:tensorflow:Finished evaluation at 2020-04-07-19:15:45\n",
            "INFO:tensorflow:Saving dict for global step 250: AUCPR = 0.7830894, global_step = 250, loss = 0.38406006\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: tmp/tfco_206861/model.ckpt-250\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'AUCPR': 0.7830894, 'global_step': 250, 'loss': 0.38406006}"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "estimator_lin.evaluate(test_input_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6xU1eK4GVKd_"
      },
      "source": [
        "## Closing Remarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zjzlHyFnC7d3"
      },
      "source": [
        "Before closing, we point out that there are three main hyper-paramters you may want to tune to improve the PR-AUC training:\n",
        "\n",
        "- `learning_rate`\n",
        "- `dual_scale`\n",
        "- `baseline_coeff`\n",
        "\n",
        "You may also be interested in exploring helpers for other similar metrics that TFCO allows you to optimize:\n",
        "- `tfco.precision_at_recall`\n",
        "- `tfco.recall_at_precision`\n",
        "- `tfco.inverse_precision_at_recall`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PRAUC_training",
      "provenance": [
        {
          "file_id": "/elided/AUCPR_training.ipynb",
          "timestamp": 1586307455441
        },
        {
          "file_id": "1QKG7HGaLhHoH0GFUYijW9PSN9Jxj3U07",
          "timestamp": 1586307357640
        },
        {
          "file_id": "1WRsmiztxL331MBAveKmv2YW5XELdSZUl",
          "timestamp": 1586202001485
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
